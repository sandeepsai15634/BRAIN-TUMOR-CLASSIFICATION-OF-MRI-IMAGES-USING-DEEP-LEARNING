{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld2WeJUp-YPM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score,log_loss\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9hB6Z-y-Zvu",
        "outputId": "c2653054-0c14-4b88-d908-68babb09ba40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twve9ue5-pQ7"
      },
      "outputs": [],
      "source": [
        "class VGG16():\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build_model(self):\n",
        "        tf.keras.backend.clear_session()\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        vgg16 = tf.keras.applications.VGG16(input_shape = self.input_shape,\n",
        "                        include_top=False,\n",
        "                        input_tensor=inputs,weights='imagenet')\n",
        "        x = vgg16.get_layer('block5_conv3').output\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        outputs = tf.keras.layers.Dense(self.num_classes, activation='softmax')(x)\n",
        "        model = tf.keras.Model(inputs, outputs)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfsmAraE_bcC"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/Training\"\n",
        "test_dir = \"/content/drive/MyDrive/Colab Notebooks/Testing\"\n",
        "target_size = (128, 128)\n",
        "batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TgPhcIMAOdd"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split = 0.15)\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest', validation_split = 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksNoG61WATwn",
        "outputId": "0e445e02-8599-4269-f1e1-b3f2430617a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4864 images belonging to 4 classes.\n",
            "Found 857 images belonging to 4 classes.\n",
            "Found 4864 images belonging to 4 classes.\n",
            "Found 857 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "og_train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    shuffle=True\n",
        ")\n",
        "og_validation_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation',\n",
        "    shuffle=True\n",
        ")\n",
        "aug_train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset = 'training',\n",
        "    shuffle=True\n",
        ")\n",
        "aug_validation_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    subset = 'validation',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdUeOpbdAYcx"
      },
      "outputs": [],
      "source": [
        "def combine_gen(*gens):\n",
        "    while True:\n",
        "        for g in gens:\n",
        "            yield next(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwJrPUitAf7P"
      },
      "outputs": [],
      "source": [
        "train_steps = (len(og_train_data)+len(aug_train_data)) // batch_size\n",
        "validation_steps = (len(og_validation_data)+len(aug_validation_data)) // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ayVYs1qAi9e",
        "outputId": "e9fc605f-edf2-47d0-b509-293b9bd228f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14716740 (56.14 MB)\n",
            "Trainable params: 14716740 (56.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "97/97 [==============================] - 794s 8s/step - loss: 1.0345 - accuracy: 0.5247 - precision: 0.7454 - recall: 0.2897 - val_loss: 1.2073 - val_accuracy: 0.5322 - val_precision: 0.6364 - val_recall: 0.2865\n",
            "Epoch 2/8\n",
            "97/97 [==============================] - 742s 8s/step - loss: 0.6803 - accuracy: 0.7103 - precision: 0.8072 - recall: 0.6000 - val_loss: 0.7552 - val_accuracy: 0.7251 - val_precision: 0.7453 - val_recall: 0.7018\n",
            "Epoch 3/8\n",
            "97/97 [==============================] - 756s 8s/step - loss: 0.5974 - accuracy: 0.7629 - precision: 0.8474 - recall: 0.6639 - val_loss: 0.6152 - val_accuracy: 0.7836 - val_precision: 0.8414 - val_recall: 0.7135\n",
            "Epoch 4/8\n",
            "97/97 [==============================] - 758s 8s/step - loss: 0.3872 - accuracy: 0.8588 - precision: 0.8920 - recall: 0.8258 - val_loss: 1.0821 - val_accuracy: 0.6550 - val_precision: 0.6974 - val_recall: 0.6199\n",
            "Epoch 5/8\n",
            "97/97 [==============================] - 754s 8s/step - loss: 0.4165 - accuracy: 0.8557 - precision: 0.8872 - recall: 0.8186 - val_loss: 0.4929 - val_accuracy: 0.8012 - val_precision: 0.8819 - val_recall: 0.7427\n",
            "Epoch 6/8\n",
            "97/97 [==============================] - 716s 7s/step - loss: 0.2813 - accuracy: 0.9144 - precision: 0.9303 - recall: 0.8948 - val_loss: 0.4287 - val_accuracy: 0.8421 - val_precision: 0.8521 - val_recall: 0.8421\n",
            "Epoch 7/8\n",
            "97/97 [==============================] - 712s 7s/step - loss: 0.2990 - accuracy: 0.8918 - precision: 0.9142 - recall: 0.8680 - val_loss: 0.2927 - val_accuracy: 0.8830 - val_precision: 0.8970 - val_recall: 0.8655\n",
            "Epoch 8/8\n",
            "97/97 [==============================] - 713s 7s/step - loss: 0.2432 - accuracy: 0.9134 - precision: 0.9336 - recall: 0.8990 - val_loss: 0.5160 - val_accuracy: 0.8538 - val_precision: 0.8742 - val_recall: 0.8129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model = VGG16(input_shape=(128,128,3), num_classes=4).build_model()\n",
        "model.summary()\n",
        "\n",
        "num_epochs = 8\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "history = model.fit(combine_gen(og_train_data, aug_train_data),\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              epochs=num_epochs,\n",
        "                              validation_data= combine_gen(og_validation_data, aug_validation_data),\n",
        "                              validation_steps = validation_steps,\n",
        "                   )\n",
        "filename = \"savedmodels/brain_tumor_VGG16.h5\"\n",
        "model.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPs9nO00AqeA"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_data)\n",
        "y_pred_labels = tf.argmax(y_pred, axis=1)\n",
        "y_true_labels = tf.constant(test_data.labels, dtype=tf.int64, shape=[1311,])\n",
        "y_pred_labels = y_pred_labels.numpy().tolist()\n",
        "y_true_labels = y_true_labels.numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpL9l3BSDXwN"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true_labels, y_pred_labels, average='weighted')\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "test_accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "test_loss = log_loss(y_true_labels, y_pred)\n",
        "\n",
        "print({\n",
        "    \"test_loss\": test_loss,\n",
        "    \"test_precision\": precision,\n",
        "    \"test_recall\": recall,\n",
        "    \"test_f1_score\": f1_score,\n",
        "    \"test_accuracy\": test_accuracy})\n",
        "\n",
        "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['glioma','meningioma','notumor', 'pituitary'])\n",
        "display.plot()\n",
        "{'test_loss': 0.24610373289909293, 'test_precision': 0.9104682424287572, 'test_recall': 0.9099923722349351, 'test_f1_score': 0.9101054250358945, 'test_accuracy': 0.9099923722349351}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fJOdI2jX20c"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['accuracy','loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVcggXDYbEVd"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15OvPysN-Gh0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}